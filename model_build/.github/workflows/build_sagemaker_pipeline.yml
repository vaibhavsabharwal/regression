name: SageMaker Pipeline with Glue Catalog
run-name: ${{ github.actor }} is building SageMaker Pipeline 🚀

on:
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: true
        default: 'warning'
        type: choice
        options:
          - info
          - warning
          - debug
  push:
    branches: [ main ]
    paths:
      - 'ml_pipelines/**'
      - 'source_scripts/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'ml_pipelines/**'
      - 'source_scripts/**'

permissions:
  id-token: write
  contents: read

jobs:
  SageMaker-Pipeline-Build:
    runs-on: ubuntu-latest

    steps:
    - name: Job Information
      run: |
        echo "🎉 The job was automatically triggered by a ${{ github.event_name }} event."
        echo "🖥️ This job is now running on a ${{ runner.os }} server hosted by GitHub!"
        echo "🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."

    - name: Check out repository code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.SAGEMAKER_PIPELINE_ROLE_ARN }}
        aws-region: ${{ secrets.REGION }}
        role-session-name: GitHubActionsSession
        role-duration-seconds: 1200

    - name: Verify AWS Credentials
      run: |
        echo "Verifying AWS credentials..."
        aws sts get-caller-identity
        echo "AWS Region set to: ${{ secrets.REGION }}"

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r ./ml_pipelines/requirements.txt

    - name: Create Requirements Directory
      run: |
        mkdir -p source_scripts/preprocessing/prepare_abalone_data/requirements
        echo "awswrangler==2.16.1" > source_scripts/preprocessing/prepare_abalone_data/requirements/requirements.txt
        echo "pymysql" >> source_scripts/preprocessing/prepare_abalone_data/requirements/requirements.txt
        echo "pandas==1.1.3" >> source_scripts/preprocessing/prepare_abalone_data/requirements/requirements.txt

    - name: Upload Files to S3
      run: |
        # Upload dataset
        python ./ml_pipelines/data/upload_s3_util.py --s3_bucket ${{ secrets.ARTIFACT_BUCKET }}
        
        # Upload requirements and code
        aws s3 cp source_scripts/preprocessing/prepare_abalone_data/main.py s3://${{ secrets.ARTIFACT_BUCKET }}/SMUSMLOPS/requirements-preprocess/input/code/main.py
        aws s3 cp --recursive source_scripts/preprocessing/prepare_abalone_data/requirements s3://${{ secrets.ARTIFACT_BUCKET }}/SMUSMLOPS/requirements-preprocess/input/dependencies/

    - name: Run Glue Catalog Pipeline
      env:
        REGION: ${{ secrets.REGION }}
        SAGEMAKER_PROJECT_NAME: ${{ secrets.SAGEMAKER_PROJECT_NAME }}
        SAGEMAKER_PROJECT_ID: ${{ secrets.SAGEMAKER_PROJECT_ID }}
        AMAZON_DATAZONE_DOMAIN: ${{ secrets.AMAZON_DATAZONE_DOMAIN }}
        AMAZON_DATAZONE_SCOPENAME: ${{ secrets.AMAZON_DATAZONE_SCOPENAME }}
        SAGEMAKER_DOMAIN_ARN: ${{ secrets.SAGEMAKER_DOMAIN_ARN }}
        SAGEMAKER_SPACE_ARN: ${{ secrets.SAGEMAKER_SPACE_ARN }}
        AMAZON_DATAZONE_PROJECT: ${{ secrets.AMAZON_DATAZONE_PROJECT }}
        MODEL_PACKAGE_GROUP_NAME: ${{ secrets.MODEL_PACKAGE_GROUP_NAME }}
        ARTIFACT_BUCKET: ${{ secrets.ARTIFACT_BUCKET }}
        SAGEMAKER_PIPELINE_ROLE_ARN: ${{ secrets.SAGEMAKER_PIPELINE_ROLE_ARN }}
        GLUE_DATABASE: ${{ secrets.GLUE_DATABASE }}
        GLUE_TABLE: ${{ secrets.GLUE_TABLE }}
      run: |
        export PYTHONUNBUFFERED=TRUE
        export SAGEMAKER_PROJECT_NAME_ID="${SAGEMAKER_PROJECT_NAME}-${SAGEMAKER_PROJECT_ID}"
        
        echo "=== Starting Glue Catalog Pipeline ==="
        python ./ml_pipelines/run_pipeline.py \
          --module-name training.pipeline \
          --role-arn "${SAGEMAKER_PIPELINE_ROLE_ARN}" \
          --tags '[{"Key":"sagemaker:project-name", "Value":"'"${SAGEMAKER_PROJECT_NAME}"'"}, {"Key":"sagemaker:project-id", "Value":"'"${SAGEMAKER_PROJECT_ID}"'"}, {"Key":"AmazonDataZoneDomain", "Value":"'"${AMAZON_DATAZONE_DOMAIN}"'"}, {"Key":"AmazonDataZoneScopeName", "Value":"'"${AMAZON_DATAZONE_SCOPENAME}"'"}, {"Key":"sagemaker:domain-arn", "Value":"'"${SAGEMAKER_DOMAIN_ARN}"'"}, {"Key":"sagemaker:space-arn", "Value":"'"${SAGEMAKER_SPACE_ARN}"'"}, {"Key":"AmazonDataZoneProject", "Value":"'"${AMAZON_DATAZONE_PROJECT}"'"}]' \
          --kwargs '{"region":"'"${REGION}"'","role":"'"${SAGEMAKER_PIPELINE_ROLE_ARN}"'","default_bucket":"'"${ARTIFACT_BUCKET}"'","pipeline_name":"githubactions-'"${SAGEMAKER_PROJECT_ID}"'","model_package_group_name":"'"${MODEL_PACKAGE_GROUP_NAME}"'","base_job_prefix":"SMUSMLOPS","glue_database_name":"'"${GLUE_DATABASE}"'","glue_table_name":"'"${GLUE_TABLE}"'"}'
        
        echo "🌟 Success: Glue Catalog Pipeline execution completed."

    - name: Job Status
      if: always()
      run: |
        echo "💯 Final job status: ${{ job.status }}"
